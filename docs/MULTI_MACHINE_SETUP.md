# Multi-Machine Embedding Generation Guide

## Overview

Run `generate_embeddings.py` on **multiple machines simultaneously** to speed up embedding generation. Each machine will automatically skip embeddings that already exist in the central database.

## âœ… How It Works

### Current Implementation (Already Working!)

The script **already supports multi-machine execution**:

1. âœ… **Checks database before generating** - Skips if embedding exists
2. âœ… **Atomic database writes** - No conflicts between machines
3. âœ… **Central database** - All machines share the same PostgreSQL database
4. âœ… **Automatic coordination** - No manual work distribution needed

### What Happens

```
Machine 1: Processing movies 1, 2, 3, 4, 5...
Machine 2: Processing movies 1, 2, 3, 4, 5...
Machine 3: Processing movies 1, 2, 3, 4, 5...

Result:
- Movie 1: Machine 1 generates (others skip)
- Movie 2: Machine 2 generates (others skip)
- Movie 3: Machine 3 generates (others skip)
- Movie 4: Machine 1 generates (others skip)
- ...
```

Each machine checks the database in real-time, so they naturally distribute the work!

## ðŸš€ Quick Start

### Step 1: Setup Each Machine

On **each machine**, ensure you have:

1. **Python environment** with dependencies
2. **Access to central PostgreSQL database**
3. **Ollama installed** with `nomic-embed-text` model
4. **Same codebase** (git clone or copy)

### Step 2: Configure Database Connection

On **each machine**, create/update `.env` file:

```bash
# .env file (same on all machines)
DATABASE_URL=postgresql://user:password@CENTRAL_DB_IP:5432/movie_recommender

# Example with actual IP
DATABASE_URL=postgresql://postgres:mypassword@192.168.1.100:5432/movie_recommender
```

### Step 3: Run on All Machines Simultaneously

On **Machine 1**:
```bash
python scripts/generate_embeddings.py --workers 10 --batch-size 100
```

On **Machine 2**:
```bash
python scripts/generate_embeddings.py --workers 10 --batch-size 100
```

On **Machine 3**:
```bash
python scripts/generate_embeddings.py --workers 10 --batch-size 100
```

**That's it!** They'll automatically coordinate through the database.

## ðŸ“Š Performance Gains

### Single Machine
- **Speed:** 2-3 embeddings/second
- **Time for 28K movies:** ~3-4 hours

### 3 Machines
- **Speed:** 6-9 embeddings/second (combined)
- **Time for 28K movies:** ~1-1.5 hours

### 5 Machines
- **Speed:** 10-15 embeddings/second (combined)
- **Time for 28K movies:** ~30-45 minutes

## ðŸ”§ Setup Instructions

### Machine 1 (Your Main Machine)

Already setup! Just run:
```bash
python scripts/generate_embeddings.py --workers 10
```

### Machine 2 & 3 (Additional Machines)

#### 1. Install Dependencies

```bash
# Clone the repository
git clone <your-repo-url>
cd movie_recommender_system

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

#### 2. Install Ollama

```bash
# On macOS
brew install ollama

# On Linux
curl -fsSL https://ollama.com/install.sh | sh

# Start Ollama
ollama serve &

# Pull the embedding model
ollama pull nomic-embed-text
```

#### 3. Configure Database Access

Create `.env` file:
```bash
# Replace with your actual database details
DATABASE_URL=postgresql://postgres:password@192.168.1.100:5432/movie_recommender

# Ollama settings (local on each machine)
OLLAMA_HOST=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
```

#### 4. Test Connection

```bash
# Test database connection
python scripts/test_db_connection.py

# Test Ollama
python scripts/test_ollama_connection.py
```

#### 5. Run Embedding Generation

```bash
python scripts/generate_embeddings.py --workers 10 --batch-size 100
```

## ðŸŽ¯ Optimal Settings Per Machine

### MacBook M1/M2
```bash
python scripts/generate_embeddings.py --workers 8 --batch-size 100
```

### MacBook Intel
```bash
python scripts/generate_embeddings.py --workers 5 --batch-size 50
```

### Linux with GPU
```bash
python scripts/generate_embeddings.py --workers 15 --batch-size 200
```

### Linux CPU Only
```bash
python scripts/generate_embeddings.py --workers 8 --batch-size 100
```

## ðŸ“ˆ Monitoring Progress

### On Each Machine

Watch the progress bar:
```
Generating embeddings: 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9835/28099 [45:30<1:20:00, 3.78movie/s, âœ“=9500, âŠ˜=330, âœ—=5]
```

- `âœ“` = Successfully generated on this machine
- `âŠ˜` = Skipped (already exists - generated by another machine)
- `âœ—` = Failed

### Combined Progress

On any machine, check total embeddings in database:

```bash
python -c "
from database.db import get_db_manager
from database.models import MovieEmbedding

db = get_db_manager()
with db.get_session() as session:
    total = session.query(MovieEmbedding).count()
    print(f'Total embeddings in database: {total:,}')
db.close_all()
"
```

### Real-Time Monitoring Script

Create `scripts/monitor_embeddings.py`:

```python
#!/usr/bin/env python3
import time
from database.db import get_db_manager
from database.models import Movie, MovieEmbedding

db = get_db_manager()

print("Monitoring embedding progress (Ctrl+C to stop)...\n")

try:
    last_count = 0
    while True:
        with db.get_session() as session:
            total_movies = session.query(Movie).count()
            total_embeddings = session.query(MovieEmbedding).count()
            remaining = total_movies - total_embeddings
            progress = (total_embeddings / total_movies) * 100
            
            # Calculate rate
            new_embeddings = total_embeddings - last_count
            rate = new_embeddings / 10  # per second (10 second interval)
            
            print(f"\rðŸ“Š Progress: {total_embeddings:,}/{total_movies:,} ({progress:.1f}%) | "
                  f"Remaining: {remaining:,} | Rate: {rate:.1f} emb/s", end='', flush=True)
            
            last_count = total_embeddings
        
        time.sleep(10)
except KeyboardInterrupt:
    print("\n\nMonitoring stopped.")
finally:
    db.close_all()
```

Run it:
```bash
python scripts/monitor_embeddings.py
```

## ðŸ”’ Database Configuration

### Allow Remote Connections

On your **PostgreSQL server**, edit `postgresql.conf`:

```conf
# Listen on all interfaces
listen_addresses = '*'
```

Edit `pg_hba.conf`:

```conf
# Allow connections from your network
host    all    all    192.168.1.0/24    md5
```

Restart PostgreSQL:
```bash
sudo systemctl restart postgresql
```

### Firewall

Open PostgreSQL port:
```bash
# On Ubuntu/Debian
sudo ufw allow 5432/tcp

# On macOS
# System Preferences > Security & Privacy > Firewall > Firewall Options
```

## ðŸŽ® Example Workflow

### Scenario: 3 Machines, 28K Movies

**Machine 1** (MacBook M1):
```bash
python scripts/generate_embeddings.py --workers 8
# Speed: ~3 emb/s
```

**Machine 2** (MacBook M2):
```bash
python scripts/generate_embeddings.py --workers 8
# Speed: ~3 emb/s
```

**Machine 3** (Linux Desktop):
```bash
python scripts/generate_embeddings.py --workers 10
# Speed: ~4 emb/s
```

**Combined Speed:** ~10 embeddings/second
**Total Time:** ~45 minutes (instead of 3-4 hours!)

### What You'll See

**Machine 1:**
```
Generating embeddings: 40%|â–ˆâ–ˆâ–ˆâ–ˆ| 11240/28099 [30:00<45:00, 6.24movie/s, âœ“=3500, âŠ˜=7700, âœ—=40]
```

**Machine 2:**
```
Generating embeddings: 40%|â–ˆâ–ˆâ–ˆâ–ˆ| 11240/28099 [30:00<45:00, 6.24movie/s, âœ“=3800, âŠ˜=7400, âœ—=40]
```

**Machine 3:**
```
Generating embeddings: 40%|â–ˆâ–ˆâ–ˆâ–ˆ| 11240/28099 [30:00<45:00, 6.24movie/s, âœ“=4000, âŠ˜=7200, âœ—=40]
```

Notice:
- All show same total progress (40%)
- Each has different `âœ“` (success) counts
- High `âŠ˜` (skipped) counts - they're coordinating!

## ðŸš¨ Troubleshooting

### "Connection refused" Error

**Problem:** Can't connect to database from other machines.

**Solution:**
1. Check PostgreSQL is listening on all interfaces
2. Check firewall allows port 5432
3. Check `pg_hba.conf` allows remote connections
4. Test with: `psql -h DB_IP -U postgres -d movie_recommender`

### High Skip Rate on All Machines

**Problem:** All machines showing high `âŠ˜` (skipped) count.

**Solution:** This is normal! It means they're coordinating well. As long as the total in database is increasing, it's working.

### One Machine Much Slower

**Problem:** One machine has lower `âœ“` count.

**Solution:** 
- Reduce `--workers` on that machine
- Check Ollama performance on that machine
- It's okay - faster machines will do more work

## ðŸ’¡ Pro Tips

### 1. Start All Machines at Once

Start all machines within a few minutes of each other for best distribution.

### 2. Use Different Batch Sizes

Faster machines can use larger batches:
```bash
# Fast machine
python scripts/generate_embeddings.py --workers 15 --batch-size 200

# Slow machine
python scripts/generate_embeddings.py --workers 5 --batch-size 50
```

### 3. Monitor from One Machine

Run the monitoring script on one machine to see combined progress.

### 4. Stop and Resume Anytime

You can stop any machine (Ctrl+C) and restart later. Progress is saved in the database.

### 5. Add More Machines Anytime

You can add more machines even while others are running!

## âœ… Summary

**Setup:**
1. Install dependencies on each machine
2. Configure `.env` with central database URL
3. Install Ollama on each machine

**Run:**
```bash
# On all machines simultaneously
python scripts/generate_embeddings.py --workers 10
```

**Monitor:**
```bash
# On any machine
python scripts/monitor_embeddings.py
```

**Result:**
- 3 machines = 3x faster
- 5 machines = 5x faster
- Automatic coordination through database
- No conflicts, no manual work distribution

ðŸš€ **You're ready to go!**

